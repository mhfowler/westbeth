{% extends "snippets/bell_labs.html" %}
{% block post_content %}

<div>
    <strong>
        COMPUTING MACHINERY AND INTELLIGENCE
    <br>
    By A. M. Turing
    </strong>
    <br>
    (an excerpt)
    <br><br>
    The short answer to this argument is that although it is established that there are
    limitations to the Powers of any particular machine, it has only been stated, without
    any sort of proof, that no such limitations apply to the human intellect. But I do not
    think this view can be dismissed quite so lightly. Whenever one of these machines
    is asked the appropriate critical question, and gives a definite answer, we know that
    this answer must be wrong, and this gives us a certain feeling of superiority. Is this
    feeling illusory? It is no doubt quite genuine, but I do not think too much
    importance should be attached to it. We too often give wrong answers to questions
    ourselves to be justified in being very pleased at such evidence of fallibility on the
    part of the machines. Further, our superiority can only be felt on such an occasion
    in relation to the one machine over which we have scored our petty triumph. There
    would be no question of triumphing simultaneously over all machines. In short,
    then, there might be men cleverer than any given machine, but then again there
    might be other machines cleverer again, and so on
</div>

{% endblock %}